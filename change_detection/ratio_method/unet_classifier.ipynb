{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Detection - Deep Learning on Image Ratios\n",
    "\n",
    "### Summary\n",
    "This notebook trains a Convolutional Neural Network (CNN) to identify building change from the pixel ratios between before/after [Sentinel-2](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/overview) imagery. For a better understanding of the ratio method begin with `change_detection.ipynb`. The model is trained on the pixel ratios of pre- & post-disaster imagery for events in the Caribbean. Ground truth building damage data is gathered from [Copernicus EMS](https://emergency.copernicus.eu/mapping/map-of-activations-rapid#zoom=3&lat=29.18235&lon=-70.57787&layers=BT00).\n",
    "\n",
    "If you already have a trained model and simply wish to evaluate it's output at a new location, skip to section 5 after section 1.\n",
    "\n",
    "### Contents\n",
    "- 1 - [Visualise Ratio & Damage Labels](#trLabels)\n",
    "- 2 - [Training Images](#trImages)\n",
    "- 3 - [Build Model](#buildModel)\n",
    "- 4 - [Train Model](#trainModel)\n",
    "- 5 - [Predictions](#Predictions)\n",
    "- 6 - [Evaluate Prediction Accuracy](#PredictionAccuracy)\n",
    "- 7 - [Test Location](#TestLocation)\n",
    "\n",
    "### Requirements\n",
    "- Lat/Long of desired location\n",
    "- Before and after dates for change detection\n",
    "- Output of damages at location if evaluating model\n",
    "\n",
    "__________________________\n",
    "### Initialisation steps - Define variables & import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define location, dates and satellite\n",
    "location = 'Roseau' # Name for saved .pngs\n",
    "lat, lon = 15.3031, -61.3834 # Center of Area of Interest \n",
    "zoom = 15 # Map tile zoom, default 16\n",
    "st_date, end_date = ['2017-08-15', '2017-10-01'], ['2017-09-15', '2017-12-01'] # Timeframes for before-after imagery: start 1, start 2; end 1 ,end 2\n",
    "satellite = \"sentinel-2:L1C\" # Descartes product name\n",
    "bands = ['red','green','blue'] # Bands used for visualisation\n",
    "cloudFraction = 0.05 # May need adjusted to get images from appropriate dates for Sentinel\n",
    "\n",
    "\n",
    "## Testing \n",
    "preModel = \"models/optimalModel\" # Use a pre-trained model - if training leave as \"\"\n",
    "deployed = False # Run model for area without damage assessment\n",
    "\n",
    "# If a damage geojson already exists for location - else leave as \"\"\n",
    "dmgJsons = \"\"  # Damage file name qualifying location and area size if already exists\n",
    "\n",
    "# Form new damage assessment json from Copernicus EMS database\n",
    "dmgAssess = \"gradings/EMSR246_04ROSEAU_02GRADING_v1_5500_settlements_point_grading.dbf\" # Copernicus EMS damage assessment database location (.dbf file needs .prj,.shp,.shx in same directory)\n",
    "grades = ['Completely Destroyed','Highly Damaged'] # Copernicus EMS labels included, options: 'Not Applicable','Negligible to slight damage', 'Moderately Damaged', 'Highly Damaged'\n",
    "area = 0.0004 # Building footprint diameter in lat/long degrees (0.0001~10m at equator)\n",
    "newDmgLocation = 'geojsons/'+location+'Damage'+str(area)[2:]+'g'+str(len(grades))+'.geojson' # Location for newly created damage .json\n",
    "\n",
    "\n",
    "## Training - Model training input\n",
    "resolution = 10 # Resolution of satellite imagery -> 10 if Sentinel\n",
    "tilesize, pad, trainArea = 16, 0, 0.0003 # Tilesize for rastering -> 32 as default, tile padding\n",
    "records = \"records/\"+location+str(trainArea)[2:]+\"g\"+str(len(grades))+\"x\"+str(tilesize)+\"p\"+str(pad)+\".tfrecords\" # Name of file for training labels\n",
    "learning_rate, epochs, batch_size, n_samples = 1e-3, 50, 8, 2000 # Model training parameters\n",
    "modelName = \"models/\"+location+\"g\"+str(len(grades))+\"ts\"+str(tilesize)+\"pd\"+str(pad)+\"lr\"+str(learning_rate)[2:]+\"e\"+str(epochs)+\"bs\"+str(batch_size)+\"a\"+str(trainArea)[2:]+\"n\"+str(n_samples) if preModel is \"\" else preModel # Define output model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# Python libraries\n",
    "import IPython\n",
    "import ipywidgets\n",
    "import ipyleaflet\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import geojson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# Library functions\n",
    "from tqdm import tqdm\n",
    "from ipyleaflet import Map, GeoJSON, GeoData, LegendControl\n",
    "from shapely.geometry import Polygon, Point\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Descartes Labs\n",
    "import descarteslabs as dl\n",
    "import descarteslabs.workflows as wf\n",
    "\n",
    "# Custom functions\n",
    "from utils import make_ground_dataset_from_ratio_polygons, get_center_location\n",
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________\n",
    "<a id='trLabels'></a>\n",
    "## 1. Visualise Ratio & Damage Labels\n",
    "First let's extract the training labels from EMS Copernicus data and visualise them. Use magic markers below map to scale imagery properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create damage json from EMS Copernicus database\n",
    "if not deployed:\n",
    "    def createDmgJson(dmgAssess, grades,area,dmgJsons):\n",
    "        settlements = gpd.read_file(dmgAssess).to_crs({'init': 'epsg:4326'}) # Read from file\n",
    "        color_dict = {'Not Applicable':'green','Negligible to slight damage':'blue', 'Moderately Damaged':'yellow', 'Highly Damaged':'orange', 'Completely Destroyed':'red'}\n",
    "        damage = settlements[settlements.grading.isin(grades)]  # Filter settlements to be within specified damage grade and location polygon\n",
    "\n",
    "        if damage.geometry[damage.index[0]].type is not 'Polygon': # Gets point assessment damages into geojson file\n",
    "            features = []\n",
    "            for i in tqdm(damage.index):\n",
    "                poly = Polygon([[damage.geometry.x[i], damage.geometry.y[i]], [damage.geometry.x[i]+area, damage.geometry.y[i]], [damage.geometry.x[i]+area, damage.geometry.y[i]+area], [damage.geometry.x[i], damage.geometry.y[i]+area], [damage.geometry.x[i], damage.geometry.y[i]]])\n",
    "                features.append(geojson.Feature(properties={\"Damage\": damage.grading[i]}, geometry=poly))\n",
    "\n",
    "            fc = geojson.FeatureCollection(features)\n",
    "            with open(dmgJsons, 'w') as f: geojson.dump(fc, f)\n",
    "\n",
    "        else:\n",
    "            with open(dmgJsons, 'w') as f: geojson.dump(damage, f) # Puts polygon assessments into geojson file\n",
    "\n",
    "    # If geojson of damage from EMS Copernicus does not exist - create one\n",
    "    if not os.path.exists(dmgJsons) and not os.path.exists(newDmgLocation): createDmgJson(dmgAssess,grades,area,newDmgLocation)\n",
    "\n",
    "    try: fc = gpd.read_file(dmgJsons) # Read training label data from damage file\n",
    "    except: fc, dmgJsons = gpd.read_file(newDmgLocation), newDmgLocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2f02bee9a140e2b97d8e382040ec7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialise map\n",
    "m1 = wf.interactive.MapApp()\n",
    "m1.center, m1.zoom = (lat, lon), zoom\n",
    "\n",
    "# Define function which displays satellite imagery on map\n",
    "def getImage(time,bands,opacity,mapNum):\n",
    "    img = wf.ImageCollection.from_id(satellite,start_datetime=st_date[time], end_datetime=end_date[time])\n",
    "    if 'sentinel' in satellite: # Use sentinel cloud-mask band if available\n",
    "        img = img.filter(lambda img: img.properties[\"cloud_fraction\"] <= cloudFraction)\n",
    "        img = img.map(lambda img: img.mask(img.pick_bands('cloud-mask')==1))\n",
    "    mos = (img.mosaic().pick_bands(bands))\n",
    "    globals()['mos_'+str(time+1)+str(bands)] = mos\n",
    "    display = mos.visualize('Image '+str(time+1)+' '+str(bands), map=mapNum)\n",
    "    display.opacity = opacity\n",
    "\n",
    "# Display before and after images for selected bands - needs to be RGB for training this model\n",
    "for i in range(len(st_date)): getImage(i,bands,0.7,m1)\n",
    "    \n",
    "# Calculate logarithmic ratio for RGB images and display\n",
    "ratio = wf.log10(globals()['mos_1'+str(bands)] / globals()['mos_2'+str(bands)])\n",
    "rdisplay = ratio.visualize('Ratio' ,map=m1)\n",
    "rdisplay.opacity = 0\n",
    "\n",
    "# Plot damage assessment data\n",
    "if not deployed:\n",
    "    geo_data = GeoData(geo_dataframe = fc, style={\"color\": \"red\", \"fillOpacity\": 0.4}, hover_style={\"fillOpacity\": 0.5})\n",
    "    m1.add_layer(geo_data)\n",
    "\n",
    "    # Legend\n",
    "    m1.add_control(LegendControl({\"Recorded Damage\":\"#FF0000\"})) \n",
    "\n",
    "m1 # Display map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Sections 2-4 are for training a new model. If assessing perfomance on new location with damage assessments jump to [section 5](#Predictions). If evaluating change over a new area without ground data (i.e. deployed = True), jump to [section 7](#TestLocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________\n",
    "<a id='trImages'></a>\n",
    "## 2. Training images\n",
    "Next, let's make an image dataset for training. The training data for this segmentation model will be comprised of RGB image tiles with corresponding target rasters of the same size. Targets are binary rasters where 1 indicates the presence of a damaged building and 0 indicates the absence. The function below tiles the region covering the labels, it extracts the corresponding tile of the ratio image displayed above, and makes the corresponding target raster. Training pixel size can be varied in the variables section. These training data are saved as .tfRecords for efficient model training.\n",
    "\n",
    "This step will take 5-10 minutes. The dataset only has to be created once. In case the notebook is re-run with same parameters as a previous run, this cell will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(records): # If records have not already been created\n",
    "    if not os.path.exists(\"records\"): os.mkdir(\"records\") # Create directory for record output if not existing\n",
    "    trainJsons = 'geojsons/'+location+'Damage'+str(trainArea)[2:]+'g'+str(len(grades))+'.geojson'\n",
    "    if not os.path.exists(trainJsons): createDmgJson(dmgAssess,grades,trainArea,trainJsons)\n",
    "    n_samples = make_ground_dataset_from_ratio_polygons(\n",
    "        ratio,\n",
    "        trainJsons,\n",
    "        products=satellite,\n",
    "        bands=bands,\n",
    "        resolution=resolution,\n",
    "        tilesize=tilesize,\n",
    "        pad=pad,\n",
    "        start_datetime=st_date[0],\n",
    "        end_datetime=end_date[0],\n",
    "        out_file=records,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to read the TFRecords the data structure and a parsing function is defined next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features in the TFRecords file\n",
    "features = {\n",
    "    \"image/image_data\": tf.io.FixedLenSequenceFeature([], dtype=tf.float32, allow_missing=True),\n",
    "    \"image/height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    \"image/width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    \"image/channels\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    \"target/target_data\": tf.io.FixedLenSequenceFeature([], dtype=tf.float32, allow_missing=True),\n",
    "    \"target/height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    \"target/width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    \"target/channels\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    \"dltile\": tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def parse_example(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, features)\n",
    "\n",
    "    img_height = tf.cast(image_features[\"image/height\"], tf.int32)\n",
    "    img_width = tf.cast(image_features[\"image/width\"], tf.int32)\n",
    "    img_channels = tf.cast(image_features[\"image/channels\"], tf.int32)\n",
    "\n",
    "    target_height = tf.cast(image_features[\"target/height\"], tf.int32)\n",
    "    target_width = tf.cast(image_features[\"target/width\"], tf.int32)\n",
    "    target_channels = tf.cast(image_features[\"target/channels\"], tf.int32)\n",
    "\n",
    "    image_raw = tf.reshape(\n",
    "        tf.squeeze(image_features[\"image/image_data\"]),\n",
    "        tf.stack([img_height, img_width, img_channels]),\n",
    "    )\n",
    "\n",
    "    target_raw = tf.reshape(\n",
    "        tf.squeeze(image_features[\"target/target_data\"]),\n",
    "        tf.stack([target_height, target_width, target_channels]),\n",
    "    )\n",
    "\n",
    "    return image_raw, target_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple data pipeline to visualize some samples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TFRecordDataset to read images from these TFRecords\n",
    "data = tf.data.TFRecordDataset(records).map(parse_example, num_parallel_calls=4)\n",
    "data_viz = iter(data.batch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples. You can re-run this cell to iterate through the dataset.\n",
    "img, trg = next(data_viz)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 5))\n",
    "rat = ax[0].imshow(np.exp(img.numpy()).astype(np.float)[0])\n",
    "lab = ax[1].imshow(trg.numpy().astype(np.uint8)[0].squeeze())\n",
    "rat_title = ax[0].set_title(\"Ratio pixels\")\n",
    "lab_title = ax[1].set_title('Building damages (yellow)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above display shows the first training sample, displaying the image and corresponding target. Each image can have one or more damaged buildings or can be a negative image without any. You can iterate through the training images by re-running the cell above multiple times.\n",
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='buildModel'></a>\n",
    "## 3. Build Model\n",
    "\n",
    "The model architecture is a [UNet classifier](https://arxiv.org/abs/1505.04597). We'll use a pre-built implementation in [TensorFlow](https://www.tensorflow.org/)_v2 / Keras . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insure tensorflow is version 2\n",
    "assert int(tf.__version__[0]) > 1, \"Please install Tensorflow 2\"\n",
    "\n",
    "learning_rate, epochs, batch_size, n_samples = 1e-4, 10, 2, 300\n",
    "modelName = \"models/\"+location+\"g\"+str(len(grades))+\"ts\"+str(tilesize)+\"pd\"+str(pad)+\"lr\"+str(learning_rate)[2:]+\"e\"+str(epochs)+\"bs\"+str(batch_size)+\"a\"+str(trainArea)[2:]+\"n\"+str(n_samples) if preModel is \"\" else preModel # Define output model name\n",
    "\n",
    "# Build the model. We could just use the base_model but then the input size would be fixed once we load a saved model. \n",
    "# In order to be able to predict on larger tiles we create an input layer with no fixed size\n",
    "base_model = UNet()\n",
    "inputs = tf.keras.layers.Input(shape=(None, None, 3))\n",
    "model = tf.keras.Model(inputs=inputs, outputs=base_model(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compile the model and output a summary which takes three arguments:\n",
    "- Optimizer: A reasonable choice of optimizer is [Adam](https://arxiv.org/abs/1412.6980v8) - it performs well in most real-world scenarios.\n",
    "- Loss function: We will use [binary crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy) as a loss as it is suitable for binary classification problems.\n",
    "- Metric: From our experience using the simple ratio method, 0.7 precision should be achievable but a big problem is increasing recall. Therefore we will focus on this metric for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"binary_accuracy\",\"Precision\",\"Recall\"]#,\"Precision\",\"Recall\"]#tfa.metrics.F1Score(num_classes=2, threshold=0.5)#tf.keras.metrics.RecallAtPrecision(precision=0.7) #[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________\n",
    "<a id='trainModel'></a>\n",
    "## 4. Train Model\n",
    "\n",
    "We will now train the model using Stochastic Gradient Descent (SGD) with data batches.  Before training the data is shuffled before splitting into a training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train/validation set sizes\n",
    "n_train_samples = int(0.8 * n_samples)\n",
    "n_val_samples = n_samples - n_train_samples\n",
    "\n",
    "# Get data and apply transform\n",
    "data = tf.data.TFRecordDataset(\"records/HaitiAbricots0002g3x16p0.tfrecords\").map(parse_example, num_parallel_calls=4)\n",
    "def type_transform(feature, target):\n",
    "    return tf.cast(feature, tf.float32), tf.cast(target, tf.float32)\n",
    "data = data.map(type_transform, num_parallel_calls=4)\n",
    "\n",
    "# # Concatenate second training location records if wanted\n",
    "# data2 = tf.data.TFRecordDataset(\"records/HaitiAbricots0002g3x32.tfrecords\").map(parse_example, num_parallel_calls=4)\n",
    "# data2 = data2.map(type_transform, num_parallel_calls=4)\n",
    "# data = data.concatenate(data2)\n",
    "\n",
    "# # Concatenate third training location records if wanted\n",
    "# data3 = tf.data.TFRecordDataset(\"records/HaitiLesCayes0002g2x32.tfrecords\").map(parse_example, num_parallel_calls=4)\n",
    "# data3 = data3.map(type_transform, num_parallel_calls=4)\n",
    "# data = data.concatenate(data3)\n",
    "\n",
    "# Shuffle the data and split into train and validation set\n",
    "data = data.shuffle(buffer_size=300, seed=1)\n",
    "data_train = data.take(n_train_samples).repeat().batch(batch_size)\n",
    "data_val = data.skip(n_train_samples).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model! This will take a while depending on training set size and number of epochs requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(\n",
    "        data_train,\n",
    "        steps_per_epoch=n_train_samples // batch_size,\n",
    "        validation_data=data_val,\n",
    "        validation_steps=n_val_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to folder\n",
    "if not os.path.exists(\"models\"): os.mkdir(\"models\")\n",
    "tf.saved_model.save(model, modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Descartes Labs storage if you so desire\n",
    "print(modelName) # You'll have to copy this into both parts of the !zip command below\n",
    "!zip -r copyHere.zip copyHere\n",
    "print('Upload model to Storage')\n",
    "storage = dl.Storage()\n",
    "storage.set_file(modelName, modelName+\".zip\")\n",
    "os.remove(modelName+\".zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training history. Our model's loss should go down smoothly while the accuracy should go up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax[0].plot(history.history[\"loss\"], label=\"train\")\n",
    "ax[0].plot(history.history[\"val_loss\"], label=\"val\")\n",
    "ax[1].plot(history.history[list(history.history.items())[1][0]], label=\"train\")\n",
    "ax[1].plot(history.history[list(history.history.items())[3][0]], label=\"val\")\n",
    "\n",
    "ax[0].set_title(\"model loss\")\n",
    "ax[1].set_title(\"model accuracy\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"loss\")\n",
    "ax[1].set_xlabel(\"epoch\")\n",
    "ax[1].set_ylabel(list(history.history.items())[1][0])\n",
    "ax[0].legend(loc=\"upper right\")\n",
    "\n",
    "p, r = history.history[\"precision\"][epochs-1], history.history[\"recall\"][epochs-1]\n",
    "f1 = 2*(p*r)/(p+r)\n",
    "\n",
    "print(\"Training metrics - Precision: \",p,\", Recall: \",r,\", F1 Score: \",f1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_samples = 500\n",
    "data_test = tf.data.TFRecordDataset(\"records/HaitiPortSalut0004g3x32.tfrecords\").map(parse_example, num_parallel_calls=4)\n",
    "data_test = data_test.map(type_transform, num_parallel_calls=4)\n",
    "data_test = data_test.shuffle(buffer_size=1000, seed=1)\n",
    "data_test = data_test.take(n_test_samples).repeat().batch(batch_size)\n",
    "\n",
    "results = model.evaluate(data_test,\n",
    "                         batch_size=8,\n",
    "                         steps=n_test_samples//batch_size)\n",
    "\n",
    "p, r = results[2], results[3]\n",
    "f1 = 2*(p*r)/(p+r)\n",
    "print(\"F1: \",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "<a id='Predictions'></a>\n",
    "## 5. Predictions\n",
    "\n",
    "Let's take a look at some predictions made by our model. We will retrieve a tile of the ratio image from our specified test location and get the predicted change from our model. If you want to use a model you've saved to Descartes Storage mark `dl_storage` as True in next box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading model from Descartes Labs storage\n",
    "dl_storage = False\n",
    "def load_model_from_storage(storage_key):\n",
    "    \"\"\"Load TF model from DL.Storage\"\"\"\n",
    "    import tempfile\n",
    "    model_zip = tempfile.NamedTemporaryFile()\n",
    "    model_dir = tempfile.TemporaryDirectory()\n",
    "    dl.Storage().get_file(storage_key, model_zip.name)\n",
    "    os.system(\"unzip {} -d {}\".format(model_zip.name, model_dir.name))\n",
    "    os.path.join(model_dir.name, \"saved_model\")\n",
    "    model_zip.close()\n",
    "    model_dir.cleanup()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function retrieving appropriate tile of the ratio\n",
    "def get_ratio_image(dltile_key,ratio,tilesize,bands):\n",
    "    tile = dl.scenes.DLTile.from_key(dltile_key)\n",
    "    sc, ctx = dl.scenes.search(aoi=tile, products=satellite, start_datetime=st_date[0], end_datetime=end_date[0])\n",
    "    return ratio.compute(ctx).ndarray.reshape(tilesize,tilesize,len(bands)) \n",
    "\n",
    "# Function retrieving desired tile from Sentinel imagery for display\n",
    "def get_sentinel_image(dltile_key, bands):\n",
    "    tile = dl.scenes.DLTile.from_key(dltile_key)\n",
    "    sc, ctx = dl.scenes.search(aoi=tile, products=satellite, start_datetime=st_date[0], end_datetime=end_date[0])\n",
    "    im = sc.mosaic(bands=bands, ctx=ctx, bands_axis=-1)\n",
    "    return im, ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we'll put all of the necessary steps into a single function that loads the model, retrieves the ratio tile for a location specified by `dltile_key`, pre-processes the tile and performs model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(dltile_key,ratio,tilesize,bands):\n",
    "    print(\"Predict on image for dltile {}\".format(dltile_key))\n",
    "\n",
    "    # load model\n",
    "    model = load_model_from_storage(modelName) if dl_storage else load_model(modelName)\n",
    "\n",
    "    # get imagery\n",
    "    im = get_ratio_image(dltile_key,ratio,tilesize,bands)\n",
    "\n",
    "    # add batch dimension\n",
    "    im = np.expand_dims(im, axis=0).astype(np.float32)\n",
    "\n",
    "    # predict\n",
    "    pred = model.predict(im)\n",
    "\n",
    "    return im, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1084:10578\n",
      "\n",
      "Job ID: fe775619e91bb43d41cfcd52a0de773ac0720ebe657fbb9d\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  "
     ]
    }
   ],
   "source": [
    "# Type in here if you would like to change the coordinates from the map center defined in variables section.\n",
    "lat, lon, tilesize = lat, lon, tilesize\n",
    "tile = dl.scenes.DLTile.from_latlon(lat, lon, resolution=resolution, tilesize=tilesize, pad=pad) # Convert coordinates to nearest descartes labs tile with size of our choosing\n",
    "\n",
    "im, pred = predict_image(tile.key,ratio,tilesize,bands) # Run prediction function for tile\n",
    "sent, ctx = get_sentinel_image(tile.key,bands) # Get Sentinel imagery for tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple plot of predictions \n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "visBand = 0 # Choose band to visualise ratio of\n",
    "\n",
    "# Plot ratio of chosen band\n",
    "a = ax[0].imshow((im.data[0,:,:,visBand].squeeze()).astype(\"float\"), cmap ='magma')\n",
    "fig.colorbar(a, ax = ax[0])\n",
    "a_tit = ax[0].set_title(\"Ratio for \"+bands[visBand]+\" band\")\n",
    "\n",
    "# Plot identified change\n",
    "disting = pred > 0.2\n",
    "b = ax[1].imshow(disting[0].squeeze().astype(\"float\"))\n",
    "fig.colorbar(b, ax = ax[1])\n",
    "b_tit = ax[1].set_title(\"Building change classification\")\n",
    "\n",
    "# Plot confidence in prediction \n",
    "c = ax[2].imshow(pred[0].squeeze().astype(\"float\"))\n",
    "fig.colorbar(c, ax = ax[2])\n",
    "c_tit = ax[2].set_title(\"Damage probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latitude & longitude of each pixel in prediction (whether true or false)\n",
    "bounds, disting = ctx.bounds, disting[0,:,:,0] if len(disting.shape) == 4 else disting # Get bounds from tile and reduce extra dimensionality of classification matrix\n",
    "lats, longs = np.linspace(bounds[3],bounds[1],disting.shape[0]), np.linspace(bounds[0],bounds[2],disting.shape[1]) # Vector of lat, longs\n",
    "\n",
    "# Create matrix of coordinates for pixels with change detected\n",
    "xm, ym = np.meshgrid(longs,lats)\n",
    "xc, yc = xm*(disting), ym*(disting)\n",
    "\n",
    "# Get geodataframe for pixel points\n",
    "df = pd.DataFrame(columns=['Northing', 'Easting'])\n",
    "for i,j in zip(np.nonzero(xc)[0], np.nonzero(xc)[1]):\n",
    "    df = df.append({'Northing': yc[i][j],'Easting': xc[i][j]}, ignore_index=True)\n",
    "det = gpd.GeoDataFrame(df, crs={'init':ctx.bounds_crs}, geometry=gpd.points_from_xy(df.Easting, df.Northing)).to_crs({'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8df82167b1451e836620aa8905f90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialise map\n",
    "m3 = wf.interactive.MapApp()\n",
    "m3.center, m3.zoom = (lat, lon), zoom\n",
    "\n",
    "getImage(1,bands,0.7,m3) # Display sentinel imagery using function from map 1\n",
    "\n",
    "# Add layer for predicted building damages\n",
    "geo_data = GeoData(geo_dataframe = det, style={'color': 'yellow', 'radius':2, 'fillColor': 'yellow', 'opacity':1, 'weight':1.9, 'dashArray':'2', 'fillOpacity':1},\n",
    "                    hover_style={'fillColor': 'red' , 'fillOpacity': 1},\n",
    "                    point_style={'radius': 3, 'color': 'yellow', 'fillOpacity': 0.7, 'fillColor': 'yellow', 'weight': 3},\n",
    "                    name = 'Damages')\n",
    "m3.add_layer(geo_data)\n",
    "\n",
    "# Plot bounding box for damage search\n",
    "poly = gpd.GeoSeries(Polygon.from_bounds(ctx.bounds[0],ctx.bounds[1],ctx.bounds[2],ctx.bounds[3]), crs={'init':ctx.bounds_crs}).to_crs(epsg=4326)\n",
    "box = GeoData(geo_dataframe = gpd.GeoDataFrame(geometry = poly.envelope), style={'color':'black','fillOpacity':0, 'opacity':0.9})\n",
    "m3.add_layer(box)\n",
    "\n",
    "# Legend\n",
    "m3.add_control(LegendControl({\"Detected Change\":\"#FFFF00\",\"Search Area\":\"#000000\"}))\n",
    "\n",
    "m3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "<a id='PredictionAccuracy'></a>\n",
    "## 6. Evaluate Prediction Accuracy\n",
    "Finally, let's compare the prediction to known damages from Copernicus EMS assessments and evaluate the effectiveness of our learnt model.\n",
    "\n",
    "As in the ratio method notebook (`change_detection.ipynb`) we determine the accuracy by evaluating the correspondance of detected change pixels to building footprints. The metrics are as follows:\n",
    "- Precision (proportion of damage detected): $P = \\frac{True Positives}{True Positives + False Positives}$\n",
    "- Recall (proportion of detections corresponding to damage): $R = \\frac{True Positives}{True Positives + False Negatives}$\n",
    "- F1 Score: $F1 = 2x\\frac{P*R}{P+R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 102/102 [00:00<00:00, 3254.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed pixels: 102 \n",
      "Damaged buildings: 1598\n",
      "Accuracy: 1.0 \n",
      "Recall: 0.6176470588235294 \n",
      "F1 score: 0.7636363636363637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load building damages and filter for within detection area\n",
    "dmg = gpd.read_file(dmgJsons)\n",
    "filtered = gpd.GeoDataFrame(crs={'init': 'epsg:4326'})\n",
    "tilePoly = gpd.GeoSeries(Polygon.from_bounds(ctx.bounds[0],ctx.bounds[1],ctx.bounds[2],ctx.bounds[3]), crs={'init':ctx.bounds_crs}).to_crs(epsg=4326).geometry[0]\n",
    "for i in dmg.index: \n",
    "    if dmg.geometry[i].centroid.within(tilePoly):\n",
    "        filtered = filtered.append(dmg.loc[i])\n",
    "\n",
    "print('Changed pixels:',len(det), '\\nDamaged buildings:',len(dmg))\n",
    "\n",
    "# Initialise accuracy and recall vectors\n",
    "acc, rec = np.zeros([max(filtered.index)+1,1]), np.zeros([max(det.index)+1,1]) # Initialise accuracy, recall arrays\n",
    "\n",
    "# Loop through pixels to determine recall (if pixel corresponds to damaged building)\n",
    "for i in tqdm(det.index):\n",
    "    # Loop through building to determine accuracy (damaged building has been detected)\n",
    "    for j in filtered.index:\n",
    "        if det.geometry[i].within(filtered.geometry[j]):\n",
    "            rec[i,0], acc[j,0] = True, True\n",
    "\n",
    "# Calculate metrics from vector outputs\n",
    "a = sum(acc)/len(filtered)\n",
    "r = sum(rec)/len(det)\n",
    "f1 = 2*(a*r)/(a+r)\n",
    "print('Accuracy:',a[0],'\\nRecall:',r[0],'\\nF1 score:',f1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32a7d82027a4f2d8e7d2c1ed8e774d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot success of change detection in matplotlib and save figure\n",
    "# Damage detected true/false\n",
    "filtered['found'] = pd.Series(acc[filtered.index,0], index=filtered.index)\n",
    "filtPlot = filtered.plot(figsize=(12,8), column='found',legend=True,cmap='RdYlGn',alpha = 0.7)\n",
    "\n",
    "# False detection points\n",
    "points = np.vstack([rec[i] for i in det.index])\n",
    "x1, y1 = np.array(det.geometry.x)*(1-points).transpose(), np.array(det.geometry.y)*(1-points).transpose()\n",
    "x1, y1 = x1[x1 != 0], y1[y1 != 0]\n",
    "filtPlot.scatter(x1,y1,s=0.05,color='b', label='False detections')\n",
    "filtPlot.set_xlim([tilePoly.bounds[0], tilePoly.bounds[2]])\n",
    "filtPlot.set_ylim([tilePoly.bounds[1], tilePoly.bounds[3]])\n",
    "\n",
    "# # Set titles and save\n",
    "# plt.set_title('Threshold:'+str(threshold)+', Area:'+str(area)+', Kernel:'+str(kSize)+' - Acc:'+str(a[0])[:6]+', Re:'+str(r[0])[:6])\n",
    "# plt.legend()\n",
    "# plt.figure.savefig('results/'+location+'_t'+str(threshold)[2:]+'a'+str(area)[2:]+'g'+str(len(grades))+str(bands)+'.png')\n",
    "\n",
    "## Display on interactive map\n",
    "# Initialise map\n",
    "m4 = wf.interactive.MapApp()\n",
    "m4.center, m4.zoom = (lat, lon), zoom\n",
    "\n",
    "# Plot background imagery as image 2 using function from map 1\n",
    "getImage(1,bands,0.7,m4)\n",
    "\n",
    "det_data = GeoData(geo_dataframe = det, style={'color': 'blue', 'radius':2, 'fillColor': 'blue', 'opacity':0.7, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.7},\n",
    "                    point_style={'radius': 3, 'color': 'blue', 'fillOpacity': 0.7, 'fillColor': 'blue', 'weight': 3}, name = 'Damages')\n",
    "m4.add_layer(det_data)\n",
    "\n",
    "# Add layers for building polygons whether red for not found, green for found\n",
    "not_found = GeoData(geo_dataframe = filtered.loc[filtered['found']==0], style={'color': 'red', 'radius':2, 'fillColor': 'red', 'opacity':0.7, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.7},\n",
    "                    hover_style={'fillColor': 'red' , 'fillOpacity': 0.5},\n",
    "                    name = 'Damages')\n",
    "found = GeoData(geo_dataframe = filtered.loc[filtered['found']==1], style={'color': 'green', 'radius':2, 'fillColor': 'green', 'opacity':0.7, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.7},\n",
    "                    hover_style={'fillColor': 'green' , 'fillOpacity': 0.5},\n",
    "                    name = 'Damages')\n",
    "m4.add_layer(not_found)\n",
    "m4.add_layer(found)\n",
    "\n",
    "# Plot bounding box for damage search\n",
    "poly = gpd.GeoSeries(Polygon.from_bounds(ctx.bounds[0],ctx.bounds[1],ctx.bounds[2],ctx.bounds[3]), crs={'init':'EPSG:32618'}).to_crs(epsg=4326)\n",
    "box = GeoData(geo_dataframe = gpd.GeoDataFrame(geometry = poly.envelope), style={'color':'yellow','fillOpacity':0, 'opacity':0.9})\n",
    "m4.add_layer(box)\n",
    "\n",
    "# Legend\n",
    "m4.add_control(LegendControl({\"Damage Identified\":\"#008000\", \"Damage Not Identified\":\"#FF0000\", \"Detected Change\":\"#0000FF\", \"Search Area\":\"#FFFF00\"}))\n",
    "\n",
    "m4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "<a id='TestLocation'></a>\n",
    "## 7. Test Location\n",
    "Beyond predicting for a single tile, we would like to evaluate the model's performance over an arbitrary wider area. For this let's draw a polygon over the desired area. Then, each corresponding tile will individually be fed in to the model for assessing change detection. If over a location with ground data, accuracy will then be evaluated for the combined output for all tiles.\n",
    "> One could question the decision not to just increase tilesize. However not only does this method make the evaluation area more flexible, but also the model does not cater well for tile sizes larger than that for which it was trained due to the input layer structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6f6f70a5124720b09a29bf06a75113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[15.3031, -61.3834], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display map upon which to draw Polygon for analysis\n",
    "r = 10*area\n",
    "testPoly = ipyleaflet.Polygon(locations=[(lat-r, lon-r), (lat-r, lon+r), (lat+r, lon+r),(lat+r, lon-r)], color=\"yellow\", fill_color=\"yellow\", transform=True)\n",
    "\n",
    "pos = Map(center=(lat, lon), zoom=zoom)\n",
    "if not deployed:\n",
    "    pos.add_layer(geo_data)\n",
    "    pos.add_control(LegendControl({\"Recorded Damage\":\"#FF0000\"})) \n",
    "pos.add_layer(testPoly)\n",
    "\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all functions required for obtaining detections\n",
    "if deployed: # Define functions if not defined in section 5\n",
    "    # Function retrieving appropriate tile of the ratio\n",
    "    def get_ratio_image(dltile_key,ratio,tilesize,bands):\n",
    "        tile = dl.scenes.DLTile.from_key(dltile_key)\n",
    "        sc, ctx = dl.scenes.search(aoi=tile, products=satellite, start_datetime=st_date[0], end_datetime=end_date[0])\n",
    "        return ratio.compute(ctx).ndarray.reshape(tilesize,tilesize,len(bands)) \n",
    "\n",
    "    # Function retrieving desired tile from Sentinel imagery for display\n",
    "    def get_sentinel_image(dltile_key, bands):\n",
    "        tile = dl.scenes.DLTile.from_key(dltile_key)\n",
    "        sc, ctx = dl.scenes.search(aoi=tile, products=satellite, start_datetime=st_date[0], end_datetime=end_date[0])\n",
    "        im = sc.mosaic(bands=bands, ctx=ctx, bands_axis=-1)\n",
    "        return im, ctx\n",
    "    \n",
    "    # Function running predict image for each tile\n",
    "    def predict_image(dltile_key,ratio,tilesize,bands):\n",
    "        print(\"Predict on image for dltile {}\".format(dltile_key))\n",
    "\n",
    "        # load model\n",
    "        model = load_model(modelName)\n",
    "\n",
    "        # get imagery\n",
    "        im = get_ratio_image(dltile_key,ratio,tilesize,bands)\n",
    "\n",
    "        # add batch dimension\n",
    "        im = np.expand_dims(im, axis=0).astype(np.float32)\n",
    "\n",
    "        # predict\n",
    "        pred = model.predict(im)\n",
    "\n",
    "        return im, pred\n",
    "\n",
    "## Function to get detections for each tile\n",
    "def testTile(lat,lon,tilesize,threshold):\n",
    "    tile = dl.scenes.DLTile.from_latlon(lat, lon, resolution=resolution, tilesize=tilesize, pad=pad) # Convert coordinates to nearest descartes labs tile with size of our choosing\n",
    "\n",
    "    im, pred = predict_image(tile.key,ratio,tilesize,bands) # Run prediction function for tile\n",
    "    sent, ctx = get_sentinel_image(tile.key,bands) # Get Sentinel imagery for tile\n",
    "\n",
    "    disting = pred > threshold # Get damaged predictions\n",
    "    \n",
    "    # Extract latitude & longitude of each pixel in prediction (whether true or false)\n",
    "    bounds, disting = ctx.bounds, disting[0,:,:,0] if len(disting.shape) == 4 else disting # Get bounds from tile and reduce extra dimensionality of classification matrix\n",
    "    lats, longs = np.linspace(bounds[3],bounds[1],disting.shape[0]), np.linspace(bounds[0],bounds[2],disting.shape[1]) # Vector of lat, longs\n",
    "\n",
    "    # Create matrix of coordinates for pixels with change detected\n",
    "    xm, ym = np.meshgrid(longs,lats)\n",
    "    xc, yc = xm*(disting), ym*(disting)\n",
    "\n",
    "    # Get geodataframe for pixel points\n",
    "    df = pd.DataFrame(columns=['Northing', 'Easting'])\n",
    "    for i,j in zip(np.nonzero(xc)[0], np.nonzero(xc)[1]):\n",
    "        df = df.append({'Northing': yc[i][j],'Easting': xc[i][j]}, ignore_index=True)\n",
    "    det = gpd.GeoDataFrame(df, crs={'init':ctx.bounds_crs}, geometry=gpd.points_from_xy(df.Easting, df.Northing)).to_crs({'init': 'epsg:4326'})\n",
    "    \n",
    "    return det, ctx    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping through tiles may take a while depending on polygon size and tile size. About 8 seconds per tile requested on 16GB RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles requested: 48 . Approximately 384 seconds on 16GB RAM.\n",
      "Predict on image for dltile 16:0:10.0:20:1080:10574\n",
      "\n",
      "Job ID: 271c50543c002adf2b23d279c5f743d7e8c7a2bba686b3d5\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|        | 1/8 [00:14<01:44, 14.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1081:10574\n",
      "\n",
      "Job ID: 1e560c173295a26237dce7d94d2af8499455d551a39b6a9e\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|       | 2/8 [00:27<01:24, 14.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1083:10574\n",
      "\n",
      "Job ID: 6a40449c92d8d1a52ce3e27df7135298bc4985fa54d0c38c\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|      | 3/8 [00:37<01:05, 13.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1084:10574\n",
      "\n",
      "Job ID: cd9b64cc721aeb29c86ca82bb89e068de0975914a81d3a09\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa314d46b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|     | 4/8 [00:49<00:50, 12.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1085:10574\n",
      "\n",
      "Job ID: 4b980ee453fb9987229c547075c725867ca3b1640b4b880e\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa314cc2200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|   | 5/8 [01:00<00:36, 12.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1086:10574\n",
      "\n",
      "Job ID: f75460a303c534139f8c0a209530eb86a91636f88a8aac94\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa308c1fef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|  | 6/8 [01:10<00:22, 11.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1087:10574\n",
      "\n",
      "Job ID: 55c81a511b993524bdafceef59f1d1897dfffe2a3dbdf6c2\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa308a4f8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%| | 7/8 [01:21<00:11, 11.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1088:10574\n",
      "\n",
      "Job ID: 7408f1b0d6dbc9c0f0768af3784c2b1f09cd70c94816bbae\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2fcac05f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 8/8 [01:30<00:00, 11.37s/it]\u001b[A\n",
      " 17%|        | 1/6 [01:30<07:34, 91.00s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1080:10576\n",
      "\n",
      "Job ID: c21ff31aa898af89f8d0b5ac5f51db50bb4732db5e64cf30\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2f1195950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|        | 1/8 [00:11<01:21, 11.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1081:10576\n",
      "\n",
      "Job ID: 66a6066a3b2526fdd02abac6323d4898bef39596c3b4b9cc\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa31445e170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|       | 2/8 [00:18<01:00, 10.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1083:10576\n",
      "\n",
      "Job ID: 50ecf4b5850d5fe3fad68d77e9dad52b8ea8437ba8728b60\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2e58fef80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|      | 3/8 [00:29<00:51, 10.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1084:10576\n",
      "\n",
      "Job ID: 00030c0eb59255cccf00f08f709fef31cdb280d0f35b6eb8\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2ddfa7830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|     | 4/8 [00:35<00:36,  9.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1085:10576\n",
      "\n",
      "Job ID: b1a6ea69998fbaa58f4c4c8276d6c54c3319835e481d02a9\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2dde1bb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|   | 5/8 [00:46<00:29,  9.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1086:10576\n",
      "\n",
      "Job ID: cb6f026a13f6af2459a11f5303920893e62371983c0f16da\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2dc71e7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|  | 6/8 [00:56<00:19,  9.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1087:10576\n",
      "\n",
      "Job ID: 0799ffcd4f0d6ec8e91a7faef97bd7e0288416a4a636841a\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2d2de7200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%| | 7/8 [01:02<00:08,  8.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1088:10576\n",
      "\n",
      "Job ID: fc4d96032cdcfcf7f8e05c15e9a5e70745aace182069a978\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2d14dad40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 8/8 [01:08<00:00,  8.60s/it]\u001b[A\n",
      " 33%|      | 2/6 [02:39<05:37, 84.34s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1080:10577\n",
      "\n",
      "Job ID: f2c608d7edb6b0592259144490f61e6795f89d9fc04494df\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2d2c47b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|        | 1/8 [00:13<01:31, 13.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1081:10577\n",
      "\n",
      "Job ID: 14f8835b2743533890455152eb8d5a0dfdf65623e9001ede\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2d0accd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|       | 2/8 [00:24<01:14, 12.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1083:10577\n",
      "\n",
      "Job ID: 71893ae6a62d7fdc3d67340045d94a6561b60704a8508e0b\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2ceb9d830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|      | 3/8 [00:35<01:00, 12.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1084:10577\n",
      "\n",
      "Job ID: 4d92d94914a2407f446dc02fbaf4dabfb683a67c914a8125\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2cd2940e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|     | 4/8 [00:54<00:56, 14.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1085:10577\n",
      "\n",
      "Job ID: 717b819fee03c3296afb98666b98602186ac8386de79dab7\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2cb9a0830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|   | 5/8 [01:00<00:35, 11.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1086:10577\n",
      "\n",
      "Job ID: 81a07a383707d907fce31ffa7b73df2197503505f9024bae\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2cd24af80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|  | 6/8 [01:07<00:20, 10.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1087:10577\n",
      "\n",
      "Job ID: 2faa670814f8cc7c00f76c971cbfebe4e2f5a73f913e4b4d\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2cd24a290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%| | 7/8 [01:20<00:10, 10.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1088:10577\n",
      "\n",
      "Job ID: 7e972ff2fd9c897e1eef2a86e85377fb2f6a2049dd8082a5\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2c98dfef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 8/8 [01:26<00:00, 10.81s/it]\u001b[A\n",
      " 50%|     | 3/6 [04:06<04:14, 84.97s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1080:10578\n",
      "\n",
      "Job ID: 0adc483dba20ed660c98489bf746c316d24f5d5510979e55\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2c7fd9d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|        | 1/8 [00:06<00:45,  6.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1081:10578\n",
      "\n",
      "Job ID: f09d770471cdb2caf5b06535a697e3c5d0fa9b4bfd8127b1\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2c66e7050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|       | 2/8 [00:13<00:40,  6.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1083:10578\n",
      "\n",
      "Job ID: d1668d11495b00d7158e120b10f9e4b6a18f7c5e139d65e3\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa77c379cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|      | 3/8 [00:21<00:34,  6.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1084:10578\n",
      "\n",
      "Job ID: 206628d5632bc493cadd2544cedc87f9e38da94a67bda5c3\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2c6656950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|     | 4/8 [00:27<00:27,  6.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1085:10578\n",
      "\n",
      "Job ID: f81d0ba5abdc70b0c9826c1fbf0632c69a6e137a1083d40a\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2c45f8320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|   | 5/8 [00:40<00:25,  8.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1086:10578\n",
      "\n",
      "Job ID: bde7aba4b2af1d0db7f6f6523468069f7e59948b462c6120\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2c2d01cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|  | 6/8 [00:51<00:18,  9.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1087:10578\n",
      "\n",
      "Job ID: 1f5f11ced3d2a5133cd7edf2a2483f2e4bd97de3fab48e6e\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2c1401f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%| | 7/8 [00:58<00:08,  8.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1088:10578\n",
      "\n",
      "Job ID: d39563999cb1799c57c2c42712b5bcedb64bdbd2d9c52041\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2bfaf8cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 8/8 [01:04<00:00,  8.09s/it]\u001b[A\n",
      " 67%|   | 4/6 [05:11<02:37, 78.91s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1080:10579\n",
      "\n",
      "Job ID: ebfda61b0975b6866ca8123eb12874429f836d8efba54f0e\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2bfaf8a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|        | 1/8 [00:06<00:47,  6.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1081:10579\n",
      "\n",
      "Job ID: e53d926e8ba44597a68765847f0d15762f931eb7aefeedeb\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2bc921290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|       | 2/8 [00:14<00:41,  6.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1083:10579\n",
      "\n",
      "Job ID: 9764707a5f2b76308b66ae4f86b9c2d2cfa6047d436c91df\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2bc7ed830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|      | 3/8 [00:27<00:43,  8.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1084:10579\n",
      "\n",
      "Job ID: a640dd1345d4097ad8ce2d8a6f83ebe6431cca726a9f13b7\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2ca47e9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|     | 4/8 [00:35<00:34,  8.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1085:10579\n",
      "\n",
      "Job ID: 2cea7e2f1cf4f4de8646bdfa9da2d1561d3197ce92baabd3\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2c3ae9290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|   | 5/8 [00:47<00:28,  9.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1086:10579\n",
      "\n",
      "Job ID: 35069e46f4458390b78b8a175bdfbea74ca4d431c9bacaea\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2ba87c680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|  | 6/8 [00:59<00:20, 10.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1087:10579\n",
      "\n",
      "Job ID: 9ed15ebc81aee6a62b3574b3a816e2a8b6ed74f535514eb0\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2b8f8ce60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%| | 7/8 [01:12<00:11, 11.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1088:10579\n",
      "\n",
      "Job ID: 66f13bb5e46ee677cfd41421026fbe79f92e8581e9805518\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2b769f050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 8/8 [01:19<00:00, 10.00s/it]\u001b[A\n",
      " 83%| | 5/6 [06:30<01:19, 79.23s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1080:10580\n",
      "\n",
      "Job ID: c4b5ecf2c107c6acd5b37b69665feaf1a6c2a3f5ebbb31b2\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2b5d9c7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|        | 1/8 [00:07<00:49,  7.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1081:10580\n",
      "\n",
      "Job ID: 3195c2a3f4524bc19d2cc3329fe27660d818d9b38b9083f8\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2b448e290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|       | 2/8 [00:20<00:53,  8.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1083:10580\n",
      "\n",
      "Job ID: 104f7a7cf4f4f117168c6df0fb98d2b127e021295f237697\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2b2bc9a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|      | 3/8 [00:29<00:45,  9.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1084:10580\n",
      "\n",
      "Job ID: f6a9fcaf444d808ab671be2909e75909aa05e0ae3db9bf2a\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2b43083b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|     | 4/8 [00:42<00:41, 10.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1085:10580\n",
      "\n",
      "Job ID: 4cc5c0dd4537c4cb39e4a348e2e6c33d09309b2a21d8f8f8\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2bdb1e710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|   | 5/8 [00:50<00:28,  9.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1086:10580\n",
      "\n",
      "Job ID: f306a86316941b10c7dd1e230ed3873f74ffeabfec0f8962\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2b24475f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|  | 6/8 [01:03<00:21, 10.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1087:10580\n",
      "\n",
      "Job ID: b254c1b33f113aecfc99ef25dcc25de9a962b5fb7fe72c41\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2b0b49320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%| | 7/8 [01:10<00:09,  9.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on image for dltile 16:0:10.0:20:1088:10580\n",
      "\n",
      "Job ID: 072ab9dfe6d87e72cbb1dde7ce18d8e750e13f373c1d9de7\n",
      "[######] | Steps: 109/109 | Stage: SUCCEEDED                                  WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2af2434d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 8/8 [01:18<00:00,  9.84s/it]\u001b[A\n",
      "100%|| 6/6 [07:49<00:00, 78.28s/it]\n"
     ]
    }
   ],
   "source": [
    "## Loop through tiles to get all detections\n",
    "# Get latitudes and longitudes for tiles according to polygon drawn and tilesize\n",
    "tileLats = np.arange(testPoly.locations[0][0]['lat'],testPoly.locations[0][2]['lat'],resolution*1E-5*tilesize)\n",
    "tileLons = np.arange(testPoly.locations[0][0]['lng'],testPoly.locations[0][2]['lng'],resolution*1E-5*tilesize)\n",
    "print(\"Number of tiles requested:\",len(tileLats)*len(tileLons),\". Approximately\",8*len(tileLats)*len(tileLons),\"seconds on 16GB RAM.\")\n",
    "threshold = 0.5\n",
    "\n",
    "allDet = gpd.GeoDataFrame(crs={'init': 'epsg:4326'})\n",
    "allCtx = np.array([])\n",
    "for lat in tqdm(tileLats):\n",
    "    for lon in tqdm(tileLons):\n",
    "        newDet, newCtx = testTile(lat,lon,tilesize,threshold)\n",
    "        newDet.index = newDet.index + len(allDet.index)\n",
    "        allDet = allDet.append(newDet)\n",
    "        allCtx = np.append([allCtx], [np.array(newCtx.bounds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/4808 [00:00<02:44, 29.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed pixels: 4808 \n",
      "Damaged buildings: 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4808/4808 [03:10<00:00, 25.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7185714285714285 \n",
      "Recall: 0.8566971713810316 \n",
      "F1 score: 0.7815785959435083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluate against damages\n",
    "if not deployed:\n",
    "    # Load building damages and filter for within detection area\n",
    "    dmg = gpd.read_file(dmgJsons)\n",
    "    filtered = gpd.GeoDataFrame(crs={'init': 'epsg:4326'})\n",
    "\n",
    "    tilePoly = gpd.GeoSeries(Polygon.from_bounds(min(allCtx[0::4]),min(allCtx[1::4]),max(allCtx[2::4]),max(allCtx[3::4])), crs={'init':ctx.bounds_crs}).to_crs(epsg=4326).geometry[0]\n",
    "    for i in dmg.index: \n",
    "        if dmg.geometry[i].centroid.within(tilePoly):\n",
    "            filtered = filtered.append(dmg.loc[i])\n",
    "\n",
    "    print('Changed pixels:',len(allDet), '\\nDamaged buildings:',len(filtered))\n",
    "\n",
    "    # Initialise accuracy and recall vectors\n",
    "    acc, rec = np.zeros([max(filtered.index)+1,1]), np.zeros([max(allDet.index)+1,1]) # Initialise accuracy, recall arrays\n",
    "\n",
    "    # Loop through pixels to determine recall (if pixel corresponds to damaged building)\n",
    "    for i in tqdm(allDet.index):\n",
    "        # Loop through building to determine accuracy (damaged building has been detected)\n",
    "        for j in filtered.index:\n",
    "            if allDet.geometry[i].within(filtered.geometry[j]):\n",
    "                rec[i,0], acc[j,0] = True, True\n",
    "\n",
    "    # Calculate metrics from vector outputs\n",
    "    a = sum(acc)/len(filtered)\n",
    "    r = sum(rec)/len(allDet)\n",
    "    f1 = 2*(a*r)/(a+r)\n",
    "    print('Accuracy:',a[0],'\\nRecall:',r[0],'\\nF1 score:',f1[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a86bbf71adb4902a1ca20e6a8371d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\n",
       "`ipyleaflet` and/or `ipywidgets` Jupyter extensions are not installed! (or you're not in a Jupyter notebook.)\n",
       "To install for JupyterLab, run this in a cell:\n",
       "    !jupyter labextension install jupyter-leaflet @jupyter-widgets/jupyterlab-manager\n",
       "To install for plain Jupyter Notebook, run this in a cell:\n",
       "    !jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
       "Then, restart the kernel and refresh the webpage.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialise map\n",
    "m5 = wf.interactive.MapApp()\n",
    "m5.center, m5.zoom = (lat, lon), zoom\n",
    "\n",
    "getImage(1,bands,0.7,m5) # Display sentinel imagery using function from map 1\n",
    "\n",
    "# Ass layer for detections from model\n",
    "allDet_data = GeoData(geo_dataframe = allDet, style={'color': 'yellow', 'radius':2, 'fillColor': 'yellow', 'opacity':0.7, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.7},\n",
    "                    point_style={'radius': 2, 'color': 'yellow', 'fillOpacity': 0.7, 'fillColor': 'blue', 'weight': 3}, name = 'Damages')\n",
    "m5.add_layer(allDet_data)\n",
    "\n",
    "# Add layers for building polygons whether red for not found, green for found\n",
    "if not deployed:\n",
    "    filtered['found'] = pd.Series(acc[filtered.index,0], index=filtered.index)\n",
    "    all_not_found = GeoData(geo_dataframe = filtered.loc[filtered['found']==0], style={'color': 'red', 'radius':2, 'fillColor': 'red', 'opacity':0.7, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.7},\n",
    "                        hover_style={'fillColor': 'red' , 'fillOpacity': 0.5},\n",
    "                        name = 'Damages')\n",
    "    all_found = GeoData(geo_dataframe = filtered.loc[filtered['found']==1], style={'color': 'green', 'radius':2, 'fillColor': 'green', 'opacity':0.7, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.7},\n",
    "                        hover_style={'fillColor': 'green' , 'fillOpacity': 0.5},\n",
    "                        name = 'Damages')\n",
    "    m5.add_layer(all_not_found)\n",
    "    m5.add_layer(all_found)\n",
    "    \n",
    "    # Legend\n",
    "    m5.add_control(LegendControl({\"Damage Identified\":\"#008000\", \"Damage Not Identified\":\"#FF0000\", \"Detected Change\":\"#0000FF\", \"Search Area\":\"#FFFF00\"}))\n",
    "else: \n",
    "    m5.add_control(LegendControl({\"Detected Change\":\"#FFFF00\", \"Search Area\":\"#0000FF\"}))\n",
    "    \n",
    "\n",
    "# Plot bounding box for damage search\n",
    "testPoly.color, testPoly.fill_opacity = 'blue', 0\n",
    "m5.add_layer(testPoly)\n",
    "\n",
    "m5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------- END ----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
